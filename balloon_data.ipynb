{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "balloon_data",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPuTCpOXDi0yXQAQzdTgXBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kanghee-Lee/Mask-RCNN_TF/blob/master/balloon_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apdJS7A7N5hQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEYl7jp3OKD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUpCHFg1QlTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "!unzip -uq \"/content/drive/My Drive/논문구현/Mask-RCNN/FastMaskRCNN\" -d \"/content/FastMaskRCNN\"\n",
        "!cd 'FastMaskRCNN/libs/datasets/pycocotools/' && make\n",
        "!unzip -uq \"/content/drive/My Drive/논문구현/Mask-RCNN/balloon_dataset\" -d \"/content/FastMaskRCNN/data\"\n",
        "!wget http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz\n",
        "!mkdir \"/content/FastMaskRCNN/data/pretrained_models\"\n",
        "!tar -zxvf \"/content/resnet_v1_50_2016_08_28.tar.gz\" -C \"/content/FastMaskRCNN/data/pretrained_models\"\n",
        "!cd 'FastMaskRCNN/libs/' && make\n",
        "!python \"/content/FastMaskRCNN/train/train.py\"\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YesgKc90TdPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip \n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/mask_rcnn_balloon.h5 -P Mask_RCNN/\n",
        "!mkdir -p \"/content/Mask_RCNN/datasets/\"\n",
        "!unzip -uq \"balloon_dataset.zip\" -d \"/content/Mask_RCNN/datasets/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIkd9cTJTl00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import itertools\n",
        "import math\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.lines as lines\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/Mask_RCNN\")\n",
        "print(ROOT_DIR)\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "from samples.balloon import balloon\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjXDvFf6DK63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = balloon.BalloonConfig()\n",
        "BALLOON_DIR = os.path.join(ROOT_DIR, \"datasets/balloon\")\n",
        "!cd 'Mask_RCNN/datasets/balloon' && ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JEX9QNMDUM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "# Get the dataset from the releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "#!cd '/Mask_RCNN/datasets/balloon/train/' && !ls\n",
        "dataset = balloon.BalloonDataset()\n",
        "dataset.load_balloon(BALLOON_DIR, \"train\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset.num_classes))\n",
        "for i, info in enumerate(dataset.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNRBVOBVD4-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZPD40o3FMWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load random image and mask.\n",
        "image_id = random.choice(dataset.image_ids)\n",
        "image = dataset.load_image(image_id)\n",
        "print(image.shape)\n",
        "mask, class_ids = dataset.load_mask(image_id)\n",
        "print(mask)\n",
        "print(np.where(True==mask))\n",
        "print(class_ids)\n",
        "print('#'*40)\n",
        "# Compute Bounding box\n",
        "bbox = utils.extract_bboxes(mask)\n",
        "print(bbox)\n",
        "norm=utils.norm_boxes(bbox, [1365, 2048])\n",
        "print(norm)\n",
        "# Display image and additional stats\n",
        "print(\"image_id \", image_id, dataset.image_reference(image_id))\n",
        "log(\"image\", image)\n",
        "log(\"mask\", mask)\n",
        "log(\"class_ids\", class_ids)\n",
        "log(\"bbox\", bbox)\n",
        "# Display image and instances\n",
        "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9UvxriFGvPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "'''\n",
        "i=tf.keras.layers.Input(shape=(1,))\n",
        "b=tf.keras.layers.Dense(32)(i)\n",
        "m=tf.keras.models.Model(inputs=i, outputs=b)\n",
        "aa=np.array([[1, ]])\n",
        "sess=tf.Session()\n",
        "print(m([aa]))\n",
        "print(m(aa).eval(session=sess))\n",
        "print(m)\n",
        "'''\n",
        "import keras.layers as KL\n",
        "print('#'*20)\n",
        "input_image = KL.Input(\n",
        "    shape=[None, None, 3], name=\"input_image\")\n",
        "print('#'*20)\n",
        "input_image_meta = KL.Input(shape=[12,],\n",
        "                            name=\"input_image_meta\")\n",
        "print('#'*20)\n",
        "input_rpn_match = KL.Input(\n",
        "    shape=[None, 1], name=\"input_rpn_match\", dtype=tf.int32)\n",
        "input_rpn_bbox = KL.Input(\n",
        "    shape=[None, 4], name=\"input_rpn_bbox\", dtype=tf.float32)\n",
        "print('#'*20)\n",
        "# Detection GT (class IDs, bounding boxes, and masks)\n",
        "# 1. GT Class IDs (zero padded)\n",
        "input_gt_class_ids = KL.Input(\n",
        "    shape=[None], name=\"input_gt_class_ids\", dtype=tf.int32)\n",
        "# 2. GT Boxes in pixels (zero padded)\n",
        "# [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in image coordinates\n",
        "input_gt_boxes = KL.Input(\n",
        "    shape=[None, 4], name=\"input_gt_boxes\", dtype=tf.float32)\n",
        "# Normalize coordinates\n",
        "gt_boxes = KL.Lambda(lambda x: norm_boxes_graph(\n",
        "    x, K.shape(input_image)[1:3]))(input_gt_boxes)\n",
        "# 3. GT Masks (zero padded)\n",
        "# [batch, height, width, MAX_GT_INSTANCES]\n",
        "print('#'*20)\n",
        "input_gt_masks = KL.Input(\n",
        "    shape=[config.MINI_MASK_SHAPE[0],\n",
        "            config.MINI_MASK_SHAPE[1], None],\n",
        "    name=\"input_gt_masks\", dtype=bool)\n",
        "class BatchNorm(KL.BatchNormalization):\n",
        "    \"\"\"Extends the Keras BatchNormalization class to allow a central place\n",
        "    to make changes if needed.\n",
        "    Batch normalization has a negative effect on training if batches are small\n",
        "    so this layer is often frozen (via setting in Config class) and functions\n",
        "    as linear layer.\n",
        "    \"\"\"\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Note about training values:\n",
        "            None: Train BN layers. This is the normal mode\n",
        "            False: Freeze BN layers. Good when batch size is small\n",
        "            True: (don't use). Set layer in training mode even when making inferences\n",
        "        \"\"\"\n",
        "        return super(self.__class__, self).call(inputs, training=training)\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block,\n",
        "                   use_bias=True, train_bn=True):\n",
        "    \"\"\"The identity_block is the block that has no conv layer at shortcut\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        use_bias: Boolean. To use or not use a bias in conv layers.\n",
        "        train_bn: Boolean. Train or freeze Batch Norm layers\n",
        "    \"\"\"\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = KL.Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a',\n",
        "                  use_bias=use_bias)(input_tensor)\n",
        "    x = BatchNorm(name=bn_name_base + '2a')(x, training=train_bn)\n",
        "    x = KL.Activation('relu')(x)\n",
        "\n",
        "    x = KL.Conv2D(nb_filter2, (kernel_size, kernel_size), padding='same',\n",
        "                  name=conv_name_base + '2b', use_bias=use_bias)(x)\n",
        "    x = BatchNorm(name=bn_name_base + '2b')(x, training=train_bn)\n",
        "    x = KL.Activation('relu')(x)\n",
        "\n",
        "    x = KL.Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c',\n",
        "                  use_bias=use_bias)(x)\n",
        "    x = BatchNorm(name=bn_name_base + '2c')(x, training=train_bn)\n",
        "\n",
        "    x = KL.Add()([x, input_tensor])\n",
        "    x = KL.Activation('relu', name='res' + str(stage) + block + '_out')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
        "               strides=(2, 2), use_bias=True, train_bn=True):\n",
        "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        use_bias: Boolean. To use or not use a bias in conv layers.\n",
        "        train_bn: Boolean. Train or freeze Batch Norm layers\n",
        "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
        "    And the shortcut should have subsample=(2,2) as well\n",
        "    \"\"\"\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = KL.Conv2D(nb_filter1, (1, 1), strides=strides,\n",
        "                  name=conv_name_base + '2a', use_bias=use_bias)(input_tensor)\n",
        "    x = BatchNorm(name=bn_name_base + '2a')(x, training=train_bn)\n",
        "    x = KL.Activation('relu')(x)\n",
        "\n",
        "    x = KL.Conv2D(nb_filter2, (kernel_size, kernel_size), padding='same',\n",
        "                  name=conv_name_base + '2b', use_bias=use_bias)(x)\n",
        "    x = BatchNorm(name=bn_name_base + '2b')(x, training=train_bn)\n",
        "    x = KL.Activation('relu')(x)\n",
        "\n",
        "    x = KL.Conv2D(nb_filter3, (1, 1), name=conv_name_base +\n",
        "                  '2c', use_bias=use_bias)(x)\n",
        "    x = BatchNorm(name=bn_name_base + '2c')(x, training=train_bn)\n",
        "\n",
        "    shortcut = KL.Conv2D(nb_filter3, (1, 1), strides=strides,\n",
        "                         name=conv_name_base + '1', use_bias=use_bias)(input_tensor)\n",
        "    shortcut = BatchNorm(name=bn_name_base + '1')(shortcut, training=train_bn)\n",
        "\n",
        "    x = KL.Add()([x, shortcut])\n",
        "    x = KL.Activation('relu', name='res' + str(stage) + block + '_out')(x)\n",
        "    return x\n",
        "\n",
        "def resnet_graph(input_image, architecture, stage5=False, train_bn=True):\n",
        "    \"\"\"Build a ResNet graph.\n",
        "        architecture: Can be resnet50 or resnet101\n",
        "        stage5: Boolean. If False, stage5 of the network is not created\n",
        "        train_bn: Boolean. Train or freeze Batch Norm layers\n",
        "    \"\"\"\n",
        "    print('#'*20)\n",
        "    assert architecture in [\"resnet50\", \"resnet101\"]\n",
        "    # Stage 1\n",
        "    x = KL.ZeroPadding2D((3, 3))(input_image)\n",
        "    x = KL.Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=True)(x)\n",
        "    x = BatchNorm(name='bn_conv1')(x, training=train_bn)\n",
        "    x = KL.Activation('relu')(x)\n",
        "    C1 = x = KL.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "    # Stage 2\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), train_bn=train_bn)\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', train_bn=train_bn)\n",
        "    C2 = x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', train_bn=train_bn)\n",
        "    # Stage 3\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', train_bn=train_bn)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', train_bn=train_bn)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', train_bn=train_bn)\n",
        "    C3 = x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', train_bn=train_bn)\n",
        "    # Stage 4\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', train_bn=train_bn)\n",
        "    block_count = {\"resnet50\": 5, \"resnet101\": 22}[architecture]\n",
        "    for i in range(block_count):\n",
        "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block=chr(98 + i), train_bn=train_bn)\n",
        "    C4 = x\n",
        "    # Stage 5\n",
        "    if stage5:\n",
        "        x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', train_bn=train_bn)\n",
        "        x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', train_bn=train_bn)\n",
        "        C5 = x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', train_bn=train_bn)\n",
        "    else:\n",
        "        C5 = None\n",
        "    return [C1, C2, C3, C4, C5]\n",
        "_, C2, C3, C4, C5 = resnet_graph(input_image, config.BACKBONE,\n",
        "                                    stage5=True, train_bn=config.TRAIN_BN)\n",
        "# Top-down Layers\n",
        "# TODO: add assert to varify feature map sizes match what's in config\n",
        "P5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c5p5')(C5)\n",
        "P4 = KL.Add(name=\"fpn_p4add\")([\n",
        "    KL.UpSampling2D(size=(2, 2), name=\"fpn_p5upsampled\")(P5),\n",
        "    KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c4p4')(C4)])\n",
        "P3 = KL.Add(name=\"fpn_p3add\")([\n",
        "    KL.UpSampling2D(size=(2, 2), name=\"fpn_p4upsampled\")(P4),\n",
        "    KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c3p3')(C3)])\n",
        "P2 = KL.Add(name=\"fpn_p2add\")([\n",
        "    KL.UpSampling2D(size=(2, 2), name=\"fpn_p3upsampled\")(P3),\n",
        "    KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c2p2')(C2)])\n",
        "# Attach 3x3 conv to all P layers to get the final feature maps.\n",
        "P2 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p2\")(P2)\n",
        "P3 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p3\")(P3)\n",
        "P4 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p4\")(P4)\n",
        "P5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p5\")(P5)\n",
        "# P6 is used for the 5th anchor scale in RPN. Generated by\n",
        "# subsampling from P5 with stride of 2.\n",
        "P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name=\"fpn_p6\")(P5)\n",
        "\n",
        "# Note that P6 is used in RPN, but not in the classifier heads.\n",
        "rpn_feature_maps = [P2, P3, P4, P5, P6]\n",
        "mrcnn_feature_maps = [P2, P3, P4, P5]\n",
        "\n",
        "print('#'*20)\n",
        "anchors = self.get_anchors(config.IMAGE_SHAPE)\n",
        "# Duplicate across the batch dimension because Keras requires it\n",
        "# TODO: can this be optimized to avoid duplicating the anchors?\n",
        "anchors = np.broadcast_to(anchors, (config.BATCH_SIZE,) + anchors.shape)\n",
        "# A hack to get around Keras's bad support for constants\n",
        "anchors = KL.Lambda(lambda x: tf.Variable(anchors), name=\"anchors\")(input_image)\n",
        "\n",
        "# RPN Model\n",
        "rpn = build_rpn_model(1,\n",
        "                        3, 256)\n",
        "# Loop through pyramid layers\n",
        "layer_outputs = []  # list of lists\n",
        "for p in rpn_feature_maps:\n",
        "    layer_outputs.append(rpn([p]))\n",
        "# Concatenate layer outputs\n",
        "# Convert from list of lists of level outputs to list of lists\n",
        "# of outputs across levels.\n",
        "# e.g. [[a1, b1, c1], [a2, b2, c2]] => [[a1, a2], [b1, b2], [c1, c2]]\n",
        "output_names = [\"rpn_class_logits\", \"rpn_class\", \"rpn_bbox\"]\n",
        "outputs = list(zip(*layer_outputs))\n",
        "outputs = [KL.Concatenate(axis=1, name=n)(list(o))\n",
        "            for o, n in zip(outputs, output_names)]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}